{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Version note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- version 1: deberta regression without k-fold\n",
    "- version 2: deberta regression with 10-fold; train:4Knooverlap  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Results record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- version 1: cv:0.834\tlb:0.797\n",
    "- Version 2: cv:0.805   lb:0.799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 16:27:46.883760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 16:27:47.125706: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-05 16:27:47.886559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-05 16:27:47.886695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-05 16:27:47.886710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tokenizers import AddedToken\n",
    "import torch\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, DebertaV2Config\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutputWithPast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_REGRESSION = True\n",
    "\n",
    "VER=6\n",
    "\n",
    "LOAD_FROM = None\n",
    "\n",
    "COMPUTE_CV = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    train_path = '../dataset/4k_nooverlap.csv' \n",
    "    # train_path = '../dataset//13k_overlap.csv'\n",
    "    test_path = '../dataset/test.csv'\n",
    "    submission_path = '../dataset/sample_submission.csv'\n",
    "    model_dir = '/ai/users/bst/competition/model/microsoft/'\n",
    "    model_name = 'deberta-v3-large'\n",
    "    model_path = model_dir + model_name\n",
    "    output_dir = f'/ai/users/bst/competition/output_v{VER}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    n_splits = 10\n",
    "    seed = 42\n",
    "    max_length = 1536\n",
    "    lr = 1e-5\n",
    "    train_batch_size = 1\n",
    "    eval_batch_size = 1\n",
    "    gradient_accumulation_steps = 4\n",
    "    train_epochs = 3\n",
    "    weight_decay = 0.01\n",
    "    warmup_ratio = 0.05\n",
    "    num_labels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "# seed_everything(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        \n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict({\n",
    "                'essay_id': [e for e in df['essay_id']],\n",
    "                'full_text': [ft for ft in df['full_text']],\n",
    "                'label': [s for s in df['label']],\n",
    "            })\n",
    "        return ds\n",
    "        \n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example['full_text'], truncation=True, max_length=CFG.max_length\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        \n",
    "        tokenized_train = train_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        tokenized_valid = valid_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        \n",
    "        return tokenized_train, tokenized_valid, self.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是回归任务，需要修改compute_metrics_for_regression函数\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.clip(0,5).round(0), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# 如果是分类任务，需要修改compute_metrics_for_classification函数\n",
    "def compute_metrics_for_classification(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Load Data and Set Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033037</td>\n",
       "      <td>The posibilty of a face reconizing computer wo...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0065bd6</td>\n",
       "      <td>Driverless cars should not exsist it can cause...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000fe60  I am a scientist at NASA that is discussing th...      3    2.0   \n",
       "1  001ab80  People always wish they had the same technolog...      4    3.0   \n",
       "2  001bdc0  We all heard about Venus, the planet without a...      4    3.0   \n",
       "3  0033037  The posibilty of a face reconizing computer wo...      2    1.0   \n",
       "4  0065bd6  Driverless cars should not exsist it can cause...      3    2.0   \n",
       "\n",
       "   fold  \n",
       "0   2.0  \n",
       "1   7.0  \n",
       "2   4.0  \n",
       "3   3.0  \n",
       "4   4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(PATHS.train_path).sample(100, random_state=CFG.seed).reset_index(drop=True)\n",
    "data['label'] = data['score'].apply(lambda x: x-1)\n",
    "if USE_REGRESSION: \n",
    "    data[\"label\"] = data[\"label\"].astype('float32') \n",
    "else: \n",
    "    data[\"label\"] = data[\"label\"].astype('int32') \n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
    "for i, (_, val_index) in enumerate(skf.split(data, data[\"score\"])):\n",
    "    data.loc[val_index, \"fold\"] = i\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_hidden_state(backbone_outputs):\n",
    "    last_hidden_state = backbone_outputs[0]\n",
    "    return last_hidden_state\n",
    "\n",
    "\n",
    "def get_all_hidden_states(backbone_outputs):\n",
    "    all_hidden_states = torch.stack(backbone_outputs[1])\n",
    "    return all_hidden_states\n",
    "\n",
    "\n",
    "def get_input_ids(inputs):\n",
    "    return inputs[\"input_ids\"]\n",
    "\n",
    "\n",
    "def get_attention_mask(inputs):\n",
    "    return inputs[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        self.output_dim = AutoConfig.from_pretrained(\"/kaggle/input/deberta-v3-large\").hidden_size\n",
    "\n",
    "    def forward(self, inputs, backbone_outputs):\n",
    "        attention_mask = get_attention_mask(inputs)\n",
    "        last_hidden_state = get_last_hidden_state(backbone_outputs)\n",
    "\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.config = DebertaV2Config.from_pretrained(model_name)\n",
    "        self.config.num_labels = num_labels\n",
    "        self.model = DebertaV2ForSequenceClassification.from_pretrained(model_name, config=self.config)\n",
    "        self.pooling = MeanPooling()\n",
    "        self.liner = nn.Linear(self.pooling.output_dim, num_labels)\n",
    "    \n",
    "    def forward(self, inputs, labels=None):\n",
    "        outputs = self.model(**inputs)\n",
    "        backbone_outputs = outputs[0]\n",
    "        mean_pooling = self.pooling(inputs, backbone_outputs)\n",
    "        logits = self.liner(mean_pooling)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1).float(), labels.view(-1).float())\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
    "        return SequenceClassifierOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Set Training Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=PATHS.output_dir,\n",
    "#     fp16=True,\n",
    "#     learning_rate=CFG.lr,\n",
    "#     per_device_train_batch_size=CFG.train_batch_size,\n",
    "#     per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "#     gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "#     num_train_epochs=CFG.train_epochs,\n",
    "#     weight_decay=CFG.weight_decay,\n",
    "#     logging_steps=200,\n",
    "#     evaluation_strategy='steps',\n",
    "#     metric_for_best_model='qwk',\n",
    "#     greater_is_better=True,\n",
    "#     eval_steps=200,\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=200,\n",
    "#     save_total_limit=5,\n",
    "#     load_best_model_at_end=True,\n",
    "#     report_to='none',\n",
    "#     warmup_ratio=CFG.warmup_ratio,\n",
    "#     lr_scheduler_type='linear', # \"cosine\" or \"linear\" or \"constant\"\n",
    "#     optim='adamw_torch',\n",
    "#     logging_first_step=True,\n",
    "#     save_only_model=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 K Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3992/3992 [00:01<00:00, 2225.98 examples/s]\n",
      "Map: 100%|██████████| 444/444 [00:00<00:00, 2430.18 examples/s]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /ai/users/bst/competition/model/microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1001' max='2994' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1001/2994 27:49 < 55:31, 0.60 it/s, Epoch 1.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.828900</td>\n",
       "      <td>0.289470</td>\n",
       "      <td>0.770132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.403100</td>\n",
       "      <td>0.283049</td>\n",
       "      <td>0.757895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.761216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.243867</td>\n",
       "      <td>0.786744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='104' max='444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [104/444 00:11 < 00:38, 8.91 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if COMPUTE_CV:\n",
    "    for fold in range(len(data['fold'].unique())):\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=PATHS.output_dir+f'/v{fold}',\n",
    "            fp16=True,\n",
    "            learning_rate=CFG.lr,\n",
    "            per_device_train_batch_size=CFG.train_batch_size,\n",
    "            per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "            gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "            num_train_epochs=CFG.train_epochs,\n",
    "            weight_decay=CFG.weight_decay,\n",
    "            logging_steps=200,\n",
    "            evaluation_strategy='steps',\n",
    "            metric_for_best_model='qwk',\n",
    "            greater_is_better=True,\n",
    "            eval_steps=200,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=200,\n",
    "            save_total_limit=5,\n",
    "            load_best_model_at_end=True,\n",
    "            report_to='none',\n",
    "            warmup_ratio=CFG.warmup_ratio,\n",
    "            lr_scheduler_type='linear', # \"cosine\" or \"linear\" or \"constant\"\n",
    "            optim='adamw_torch',\n",
    "            logging_first_step=True,\n",
    "            save_only_model=True,\n",
    "        )\n",
    "\n",
    "        # GET TRAIN AND VALID DATA\n",
    "        train = data[data['fold'] != fold]\n",
    "        valid = data[data['fold'] == fold].copy()\n",
    "\n",
    "        # ADD NEW TOKENS for (\"\\n\") new paragraph and (\" \"*2) double space \n",
    "        tokenizer = AutoTokenizer.from_pretrained(PATHS.model_path)\n",
    "        tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "        tokenize = Tokenize(train, valid, tokenizer)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # REMOVE DROPOUT FROM REGRESSION\n",
    "        config = AutoConfig.from_pretrained(PATHS.model_path)\n",
    "        if USE_REGRESSION:\n",
    "            config.attention_probs_dropout_prob = 0.0 \n",
    "            config.hidden_dropout_prob = 0.0 \n",
    "            config.num_labels = 1 \n",
    "        else: config.num_labels = CFG.num_labels \n",
    "\n",
    "        if LOAD_FROM:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained( f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "        else:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(PATHS.model_path, config=config)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        # TRAIN WITH TRAINER\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        if USE_REGRESSION: compute_metrics = compute_metrics_for_regression\n",
    "        else: compute_metrics = compute_metrics_for_classification\n",
    "        trainer = Trainer( \n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        if LOAD_FROM is None:\n",
    "                trainer.train()\n",
    "\n",
    "        # PLOT CONFUSION MATRIX\n",
    "        y_true = valid['score'].values\n",
    "        predictions0 = trainer.predict(tokenized_valid).predictions\n",
    "        if USE_REGRESSION: \n",
    "            predictions = predictions0.round(0) + 1\n",
    "        else: \n",
    "            predictions = predictions0.argmax(axis=1) + 1 \n",
    "        cm = confusion_matrix(y_true, predictions, labels=[x for x in range(1,7)])\n",
    "        draw_cm = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=[x for x in range(1,7)])\n",
    "        draw_cm.plot()\n",
    "        plt.show()\n",
    "\n",
    "        # SAVE FOLD MODEL AND TOKENIZER\n",
    "        if LOAD_FROM is None:\n",
    "            trainer.save_model(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "            tokenizer.save_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "\n",
    "        # SAVE OOF PREDICTIONS\n",
    "        if USE_REGRESSION: \n",
    "            valid['pred'] = predictions0 + 1 \n",
    "        else:\n",
    "            COLS = [f'p{x}' for x in range(CFG.num_labels)] \n",
    "            valid[COLS] = predictions0 \n",
    "        valid.to_csv(f'outputs/valid_df_fold_{fold}_v{VER}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Overall CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid OOF shape: (4436, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00fca9b</td>\n",
       "      <td>The authors sugestion that studying venus is a...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.178396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012f8f0</td>\n",
       "      <td>In this story the author suggests that studyin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.893716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0293f31</td>\n",
       "      <td>The Facial Action Coding System is a great ach...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.213805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0499982</td>\n",
       "      <td>My position on driverless cars is that I am a ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.150983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04af97d</td>\n",
       "      <td>Driverless should not be used under any condit...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.079288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  00fca9b  The authors sugestion that studying venus is a...      3    2.0   \n",
       "1  012f8f0  In this story the author suggests that studyin...      3    2.0   \n",
       "2  0293f31  The Facial Action Coding System is a great ach...      3    2.0   \n",
       "3  0499982  My position on driverless cars is that I am a ...      3    2.0   \n",
       "4  04af97d  Driverless should not be used under any condit...      4    3.0   \n",
       "\n",
       "   fold      pred  \n",
       "0   0.0  2.178396  \n",
       "1   0.0  2.893716  \n",
       "2   0.0  4.213805  \n",
       "3   0.0  3.150983  \n",
       "4   0.0  4.079288  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if COMPUTE_CV:\n",
    "    dfs = []\n",
    "    for k in range(CFG.n_splits):\n",
    "        dfs.append( pd.read_csv(f'outputs/valid_df_fold_{k}_v{VER}.csv') )\n",
    "        os.system(f'rm outputs/valid_df_fold_{k}_v{VER}.csv')\n",
    "    dfs = pd.concat(dfs)\n",
    "    dfs.to_csv(f'outputs/valid_df_v{VER}.csv',index=False)\n",
    "    print('Valid OOF shape:', dfs.shape )\n",
    "    display( dfs.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall QWK CV = 0.8054719475951295\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_CV:\n",
    "    if USE_REGRESSION:\n",
    "        m = cohen_kappa_score(dfs.score.values, dfs.pred.values.clip(1,6).round(0), weights='quadratic')\n",
    "    else:\n",
    "        m = cohen_kappa_score(dfs.score.values, dfs.iloc[:,-6:].values.argmax(axis=1)+1, weights='quadratic')\n",
    "    print('Overall QWK CV =',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Infer Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text\n",
       "0  000d118  Many people have car where they live. The thin...\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...\n",
       "2  001ab80  People always wish they had the same technolog..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(PATHS.test_path)\n",
    "print('Test shape:', test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 224.28 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 329.04 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 202.56 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 272.43 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 217.24 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 292.28 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 233.53 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 287.87 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 261.12 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 328.93 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 236.47 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 290.06 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 242.61 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 318.03 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 237.26 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 348.07 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 229.65 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 306.01 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 250.79 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 329.58 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_pred = []\n",
    "test['label'] = 0.0\n",
    "\n",
    "for fold in range(CFG.n_splits):\n",
    "    \n",
    "    # LOAD TOKENIZER\n",
    "    if LOAD_FROM:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    tokenize = Tokenize(test, test, tokenizer)\n",
    "    tokenized_test, _, _ = tokenize()\n",
    "\n",
    "    # LOAD MODEL\n",
    "    if LOAD_FROM:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    else:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    \n",
    "    # INFER WITH TRAINER\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    trainer = Trainer( \n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_test,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # SAVE PREDICTIONS\n",
    "    predictions = trainer.predict(tokenized_test).predictions\n",
    "    all_pred.append( predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "preds = np.mean(all_pred, axis=0)\n",
    "print('Predictions shape:',preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Create Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'PATHS' has no attribute 'sub_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sub \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mPATHS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_path\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_REGRESSION: sub[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: sub[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'PATHS' has no attribute 'sub_path'"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(PATHS.sub_path)\n",
    "if USE_REGRESSION: sub[\"score\"] = preds.clip(0,5).round(0)+1\n",
    "else: sub[\"score\"] = preds.argmax(axis=1)+1\n",
    "sub.score = sub.score.astype('int32')\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "print('Submission shape:', sub.shape )\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Version note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- version 1: deberta regression without k-fold\n",
    "- version 2: deberta regression with 10-fold; train:4Knooverlap  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Results record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- version 1: cv:0.834\tlb:0.797\n",
    "- Version 2: cv:0.805   lb:0.799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 15:25:42.011927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 15:25:42.251337: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-05 15:25:42.980075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-05 15:25:42.980207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-05 15:25:42.980221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tokenizers import AddedToken\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_REGRESSION = True\n",
    "\n",
    "VER=2\n",
    "\n",
    "LOAD_FROM = None\n",
    "\n",
    "COMPUTE_CV = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    train_path = '../dataset/4k_nooverlap.csv' # v2\n",
    "    # train_path = '../dataset//13k_overlap.csv'\n",
    "    test_path = '../dataset/test.csv'\n",
    "    submission_path = '../dataset/sample_submission.csv'\n",
    "    model_dir = '/ai/users/bst/competition/model/microsoft/'\n",
    "    model_name = 'deberta-v3-large'\n",
    "    model_path = model_dir + model_name\n",
    "    output_dir = f'/ai/users/bst/competition/output_v{VER}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    n_splits = 10\n",
    "    seed = 42\n",
    "    max_length = 1536\n",
    "    lr = 1e-5\n",
    "    train_batch_size = 1\n",
    "    eval_batch_size = 1\n",
    "    gradient_accumulation_steps = 4\n",
    "    train_epochs = 3\n",
    "    weight_decay = 0.01\n",
    "    warmup_ratio = 0.05\n",
    "    num_labels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "# seed_everything(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        \n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict({\n",
    "                'essay_id': [e for e in df['essay_id']],\n",
    "                'full_text': [ft for ft in df['full_text']],\n",
    "                'label': [s for s in df['label']],\n",
    "            })\n",
    "        return ds\n",
    "        \n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example['full_text'], truncation=True, max_length=CFG.max_length\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        \n",
    "        tokenized_train = train_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        tokenized_valid = valid_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        \n",
    "        return tokenized_train, tokenized_valid, self.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是回归任务，需要修改compute_metrics_for_regression函数\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.clip(0,5).round(0), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# 如果是分类任务，需要修改compute_metrics_for_classification函数\n",
    "def compute_metrics_for_classification(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Load Data and Set Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033037</td>\n",
       "      <td>The posibilty of a face reconizing computer wo...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0065bd6</td>\n",
       "      <td>Driverless cars should not exsist it can cause...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000fe60  I am a scientist at NASA that is discussing th...      3    2.0   \n",
       "1  001ab80  People always wish they had the same technolog...      4    3.0   \n",
       "2  001bdc0  We all heard about Venus, the planet without a...      4    3.0   \n",
       "3  0033037  The posibilty of a face reconizing computer wo...      2    1.0   \n",
       "4  0065bd6  Driverless cars should not exsist it can cause...      3    2.0   \n",
       "\n",
       "   fold  \n",
       "0   2.0  \n",
       "1   7.0  \n",
       "2   4.0  \n",
       "3   3.0  \n",
       "4   4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(PATHS.train_path) # .sample(frac=1/3, random_state=CFG.seed).reset_index(drop=True)\n",
    "data['label'] = data['score'].apply(lambda x: x-1)\n",
    "if USE_REGRESSION: \n",
    "    data[\"label\"] = data[\"label\"].astype('float32') \n",
    "else: \n",
    "    data[\"label\"] = data[\"label\"].astype('int32') \n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
    "for i, (_, val_index) in enumerate(skf.split(data, data[\"score\"])):\n",
    "    data.loc[val_index, \"fold\"] = i\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Set Training Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=PATHS.output_dir,\n",
    "#     fp16=True,\n",
    "#     learning_rate=CFG.lr,\n",
    "#     per_device_train_batch_size=CFG.train_batch_size,\n",
    "#     per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "#     gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "#     num_train_epochs=CFG.train_epochs,\n",
    "#     weight_decay=CFG.weight_decay,\n",
    "#     logging_steps=200,\n",
    "#     evaluation_strategy='steps',\n",
    "#     metric_for_best_model='qwk',\n",
    "#     greater_is_better=True,\n",
    "#     eval_steps=200,\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=200,\n",
    "#     save_total_limit=5,\n",
    "#     load_best_model_at_end=True,\n",
    "#     report_to='none',\n",
    "#     warmup_ratio=CFG.warmup_ratio,\n",
    "#     lr_scheduler_type='linear', # \"cosine\" or \"linear\" or \"constant\"\n",
    "#     optim='adamw_torch',\n",
    "#     logging_first_step=True,\n",
    "#     save_only_model=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 K Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3992/3992 [00:01<00:00, 2241.86 examples/s]\n",
      "Map: 100%|██████████| 444/444 [00:00<00:00, 2476.17 examples/s]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /ai/users/bst/competition/model/microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2994' max='2994' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2994/2994 1:25:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.243500</td>\n",
       "      <td>0.285423</td>\n",
       "      <td>0.775453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.789778</td>\n",
       "      <td>0.353591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>0.255326</td>\n",
       "      <td>0.797688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.249905</td>\n",
       "      <td>0.790300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.348900</td>\n",
       "      <td>0.238857</td>\n",
       "      <td>0.825921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.237772</td>\n",
       "      <td>0.821293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.251240</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.273200</td>\n",
       "      <td>0.259761</td>\n",
       "      <td>0.803279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.235036</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.232794</td>\n",
       "      <td>0.840544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.254429</td>\n",
       "      <td>0.815718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.246464</td>\n",
       "      <td>0.831202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.247957</td>\n",
       "      <td>0.822165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.242947</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 3992/3992 [00:01<00:00, 2110.47 examples/s]\n",
      "Map: 100%|██████████| 444/444 [00:00<00:00, 2127.55 examples/s]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /ai/users/bst/competition/model/microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1201' max='2994' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1201/2994 33:29 < 50:05, 0.60 it/s, Epoch 1.20/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.776000</td>\n",
       "      <td>0.424892</td>\n",
       "      <td>0.706954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.333178</td>\n",
       "      <td>0.729505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>0.343297</td>\n",
       "      <td>0.762437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>0.349940</td>\n",
       "      <td>0.690479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>0.328483</td>\n",
       "      <td>0.743682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.314878</td>\n",
       "      <td>0.741271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 68\u001b[0m\n\u001b[1;32m     58\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer( \n\u001b[1;32m     59\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     60\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LOAD_FROM \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m         \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# PLOT CONFUSION MATRIX\u001b[39;00m\n\u001b[1;32m     71\u001b[0m y_true \u001b[38;5;241m=\u001b[39m valid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2278\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2673\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2670\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2673\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2752\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2750\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2751\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2755\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   2756\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:3252\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3249\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3252\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3254\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:3327\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3325\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   3326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3327\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3328\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   3329\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:2584\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_file, shard \u001b[38;5;129;01min\u001b[39;00m shards\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[1;32m   2583\u001b[0m         \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[0;32m-> 2584\u001b[0m         \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2585\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2586\u001b[0m         save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/safetensors/torch.py:284\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    254\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    255\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })"
     ]
    }
   ],
   "source": [
    "if COMPUTE_CV:\n",
    "    for fold in range(len(data['fold'].unique())):\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=PATHS.output_dir+f'/v{fold}',\n",
    "            fp16=True,\n",
    "            learning_rate=CFG.lr,\n",
    "            per_device_train_batch_size=CFG.train_batch_size,\n",
    "            per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "            gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "            num_train_epochs=CFG.train_epochs,\n",
    "            weight_decay=CFG.weight_decay,\n",
    "            logging_steps=200,\n",
    "            evaluation_strategy='steps',\n",
    "            metric_for_best_model='qwk',\n",
    "            greater_is_better=True,\n",
    "            eval_steps=200,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=200,\n",
    "            save_total_limit=5,\n",
    "            load_best_model_at_end=True,\n",
    "            report_to='none',\n",
    "            warmup_ratio=CFG.warmup_ratio,\n",
    "            lr_scheduler_type='linear', # \"cosine\" or \"linear\" or \"constant\"\n",
    "            optim='adamw_torch',\n",
    "            logging_first_step=True,\n",
    "            save_only_model=True,\n",
    "        )\n",
    "\n",
    "        # GET TRAIN AND VALID DATA\n",
    "        train = data[data['fold'] != fold]\n",
    "        valid = data[data['fold'] == fold].copy()\n",
    "\n",
    "        # ADD NEW TOKENS for (\"\\n\") new paragraph and (\" \"*2) double space \n",
    "        tokenizer = AutoTokenizer.from_pretrained(PATHS.model_path)\n",
    "        tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "        tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "        tokenize = Tokenize(train, valid, tokenizer)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # REMOVE DROPOUT FROM REGRESSION\n",
    "        config = AutoConfig.from_pretrained(PATHS.model_path)\n",
    "        if USE_REGRESSION:\n",
    "            config.attention_probs_dropout_prob = 0.0 \n",
    "            config.hidden_dropout_prob = 0.0 \n",
    "            config.num_labels = 1 \n",
    "        else: config.num_labels = CFG.num_labels \n",
    "\n",
    "        if LOAD_FROM:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained( f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "        else:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(PATHS.model_path, config=config)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        # TRAIN WITH TRAINER\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        if USE_REGRESSION: compute_metrics = compute_metrics_for_regression\n",
    "        else: compute_metrics = compute_metrics_for_classification\n",
    "        trainer = Trainer( \n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        if LOAD_FROM is None:\n",
    "                trainer.train()\n",
    "\n",
    "        # PLOT CONFUSION MATRIX\n",
    "        y_true = valid['score'].values\n",
    "        predictions0 = trainer.predict(tokenized_valid).predictions\n",
    "        if USE_REGRESSION: \n",
    "            predictions = predictions0.round(0) + 1\n",
    "        else: \n",
    "            predictions = predictions0.argmax(axis=1) + 1 \n",
    "        cm = confusion_matrix(y_true, predictions, labels=[x for x in range(1,7)])\n",
    "        draw_cm = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=[x for x in range(1,7)])\n",
    "        draw_cm.plot()\n",
    "        plt.show()\n",
    "\n",
    "        # SAVE FOLD MODEL AND TOKENIZER\n",
    "        if LOAD_FROM is None:\n",
    "            trainer.save_model(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "            tokenizer.save_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "\n",
    "        # SAVE OOF PREDICTIONS\n",
    "        if USE_REGRESSION: \n",
    "            valid['pred'] = predictions0 + 1 \n",
    "        else:\n",
    "            COLS = [f'p{x}' for x in range(CFG.num_labels)] \n",
    "            valid[COLS] = predictions0 \n",
    "        valid.to_csv(f'outputs/valid_df_fold_{fold}_v{VER}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Overall CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid OOF shape: (4436, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00fca9b</td>\n",
       "      <td>The authors sugestion that studying venus is a...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.178396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012f8f0</td>\n",
       "      <td>In this story the author suggests that studyin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.893716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0293f31</td>\n",
       "      <td>The Facial Action Coding System is a great ach...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.213805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0499982</td>\n",
       "      <td>My position on driverless cars is that I am a ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.150983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04af97d</td>\n",
       "      <td>Driverless should not be used under any condit...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.079288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  00fca9b  The authors sugestion that studying venus is a...      3    2.0   \n",
       "1  012f8f0  In this story the author suggests that studyin...      3    2.0   \n",
       "2  0293f31  The Facial Action Coding System is a great ach...      3    2.0   \n",
       "3  0499982  My position on driverless cars is that I am a ...      3    2.0   \n",
       "4  04af97d  Driverless should not be used under any condit...      4    3.0   \n",
       "\n",
       "   fold      pred  \n",
       "0   0.0  2.178396  \n",
       "1   0.0  2.893716  \n",
       "2   0.0  4.213805  \n",
       "3   0.0  3.150983  \n",
       "4   0.0  4.079288  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if COMPUTE_CV:\n",
    "    dfs = []\n",
    "    for k in range(CFG.n_splits):\n",
    "        dfs.append( pd.read_csv(f'outputs/valid_df_fold_{k}_v{VER}.csv') )\n",
    "        os.system(f'rm outputs/valid_df_fold_{k}_v{VER}.csv')\n",
    "    dfs = pd.concat(dfs)\n",
    "    dfs.to_csv(f'outputs/valid_df_v{VER}.csv',index=False)\n",
    "    print('Valid OOF shape:', dfs.shape )\n",
    "    display( dfs.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall QWK CV = 0.8054719475951295\n"
     ]
    }
   ],
   "source": [
    "if COMPUTE_CV:\n",
    "    if USE_REGRESSION:\n",
    "        m = cohen_kappa_score(dfs.score.values, dfs.pred.values.clip(1,6).round(0), weights='quadratic')\n",
    "    else:\n",
    "        m = cohen_kappa_score(dfs.score.values, dfs.iloc[:,-6:].values.argmax(axis=1)+1, weights='quadratic')\n",
    "    print('Overall QWK CV =',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Infer Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text\n",
       "0  000d118  Many people have car where they live. The thin...\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...\n",
       "2  001ab80  People always wish they had the same technolog..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(PATHS.test_path)\n",
    "print('Test shape:', test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 224.28 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 329.04 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 202.56 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 272.43 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 217.24 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 292.28 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 233.53 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 287.87 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 261.12 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 328.93 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 236.47 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 290.06 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 242.61 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 318.03 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 237.26 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 348.07 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 229.65 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 306.01 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 250.79 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 329.58 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_pred = []\n",
    "test['label'] = 0.0\n",
    "\n",
    "for fold in range(CFG.n_splits):\n",
    "    \n",
    "    # LOAD TOKENIZER\n",
    "    if LOAD_FROM:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    tokenize = Tokenize(test, test, tokenizer)\n",
    "    tokenized_test, _, _ = tokenize()\n",
    "\n",
    "    # LOAD MODEL\n",
    "    if LOAD_FROM:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    else:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f'/ai/users/bst/competition/outputs/{PATHS.model_name}_AES2_fold_{fold}_v{VER}')\n",
    "    \n",
    "    # INFER WITH TRAINER\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    trainer = Trainer( \n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_test,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # SAVE PREDICTIONS\n",
    "    predictions = trainer.predict(tokenized_test).predictions\n",
    "    all_pred.append( predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "preds = np.mean(all_pred, axis=0)\n",
    "print('Predictions shape:',preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Create Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'PATHS' has no attribute 'sub_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sub \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mPATHS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_path\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_REGRESSION: sub[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: sub[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'PATHS' has no attribute 'sub_path'"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(PATHS.sub_path)\n",
    "if USE_REGRESSION: sub[\"score\"] = preds.clip(0,5).round(0)+1\n",
    "else: sub[\"score\"] = preds.argmax(axis=1)+1\n",
    "sub.score = sub.score.astype('int32')\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "print('Submission shape:', sub.shape )\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
